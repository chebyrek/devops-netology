# Домашнее задание к занятию "10.01. Зачем и что нужно мониторить"

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?  

Ответ:  
 - CPU, если вычисления загружают процессор, заначит нужно следить за его загрузкой.
 - RAM, чтобы приложение не прибил OOM Killer, нужно следить за потреблением RAM
 - Диски, если отчеты сохраняются на диск, значит на нем может закончиться место или inodes, за этим нужно следить. Если сервер железный, то необходимо мониторить raid-контроллер, либо smart дисков.
 - Сетевые интерфейсы, смотреть загрузку интерфейса, количество ошибок передачи и т.п
 - Считать количество успешных и неуспешных HTTP запросов к серверу
 - Считать от кого, сколько и каких конкретно запросов пришло в API
 - получать метрики самого приложения, т.е. сколько времени занимают расчеты, сколько данных обрабатывается и т.п.  

2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, 
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы 
можете ему предложить?  

Ответ:  
Обозначить метрики, отвечающие за доступность приложения, и на основе их считать SLI.  

3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою 
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, 
чтобы разработчики получали ошибки приложения?

Ответ:  
Может я не верно понял вопрос, но имеется в виду рассмотренный на лекции подход "Логи не нужны"? Т.е. нужно попросить разработчиков обрабатывать логи непосредственно в приложении, чтобы они сразу "превращались" в полезные метрики и попадали в мониторинг, вместо того, чтобы в сыром виде попадать в систему сбора логов. 

3. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. 
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?  

Ответ:  
В формуле забыли про 3хх коды ответов, корректная формула выглядит так:  
(summ_2xx_requests + summ_3xx_requests)/(summ_all_requests)  

## Дополнительное задание (со звездочкой*) - необязательно к выполнению

Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему 
мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. Вы, как 
опытный системный-администратор, знаете, что системная информация сервера лежит в директории `/proc`. 
Также, вы знаете, что в системе Linux есть  планировщик задач cron, который может запускать задачи по расписанию.

Суммировав все, вы спроектировали приложение, которое:
- является python3 скриптом
- собирает метрики из папки `/proc`
- складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log 
(YY - год, MM - месяц, DD - день)
- каждый сбор метрик складывается в виде json-строки, в виде:
  + timestamp (временная метка, int, unixtimestamp)
  + metric_1 (метрика 1)
  + metric_2 (метрика 2)
  
     ...
     
  + metric_N (метрика N)
  
- сбор метрик происходит каждую 1 минуту по cron-расписанию

Для успешного выполнения задания нужно привести:

а) работающий код python3-скрипта,
```python
from pathlib import Path
import time
import datetime
import json

metrics = {'cpu1': Path('/proc') / 'loadavg',
            'cpu5': Path('/proc') / 'loadavg',
            'memFree': Path('/proc') / 'meminfo',
            'uptime': Path('/proc') / 'uptime'} 

def set_file_name():
    name = "-awesome-monitoring.log"
    date = datetime.datetime.today()
    return date.strftime("%y-%m-%d") + name

def get_metric(metric_name):
    metric = ''
    with open(metrics[metric_name], 'r') as file:
        content = file.read()
    if metric_name == 'cpu1':
        metric = content.split()[0]
    if metric_name == 'cpu5':
        metric = content.split()[1]
    if metric_name == 'memFree':
        for line in content.split('\n'):
            if line.startswith('MemTotal'):
                mem_total = int(line.split()[1])
            if line.startswith('MemAvailable'):
                mem_free = int(line.split()[1])
        metric = round(mem_free * 100 / mem_total)
    if metric_name == 'uptime':
        uptime = round(float(content.split()[0]))
        metric = str(datetime.timedelta(seconds=uptime))
    return metric

def main():
    result = {'timestamp':int(time.time())}

    for k in metrics.keys():
        metric = get_metric(k)
        result[k] = metric
        
    log_file = Path("/var/log") / set_file_name()

    with open(log_file,'a') as file:
        file.write(json.dumps(result))

if __name__ == "__main__":
    main()
```

б) конфигурацию cron-расписания,
```sh
$ sudo crontab -e
* * * * * python3 /home/user/proc_monitor/proc_monitor.py 2&1>/dev/null
```
в) пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не менее 5 записей,
```json
{"timestamp": 1634967121, "cpu1": "0.02", "cpu5": "0.05", "memFree": 66, "uptime": "18 days, 21:15:46"}
{"timestamp": 1634967181, "cpu1": "0.00", "cpu5": "0.04", "memFree": 66, "uptime": "18 days, 21:16:46"}
{"timestamp": 1634967241, "cpu1": "0.07", "cpu5": "0.06", "memFree": 66, "uptime": "18 days, 21:17:46"}
{"timestamp": 1634967301, "cpu1": "0.02", "cpu5": "0.04", "memFree": 66, "uptime": "18 days, 21:18:46"}
{"timestamp": 1634967361, "cpu1": "0.01", "cpu5": "0.03", "memFree": 66, "uptime": "18 days, 21:19:46"}
{"timestamp": 1634967421, "cpu1": "0.07", "cpu5": "0.04", "memFree": 66, "uptime": "18 days, 21:20:46"}
```
P.S.: количество собираемых метрик должно быть не менее 4-х.
P.P.S.: по желанию можно себя не ограничивать только сбором метрик из `/proc`.
